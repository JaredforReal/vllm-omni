# Stage config for running GLM-Image with 2-stage architecture
# Stage 0: AR Model (vLLM implementation) - generates prior_token_ids
# Stage 1: Diffusion (DiT + VAE) - denoising and image decoding

stage_args:
  # Stage 0: AR Model (GlmImageForConditionalGeneration)
  # This stage uses the vLLM-optimized AR model to generate prior tokens
  # for conditioning the diffusion process.
  - stage_id: 0
    stage_type: llm
    runtime:
      process: true
      devices: "0"
      max_batch_size: 1
    engine_args:
      model_stage: ar
      model_arch: GlmImageForConditionalGeneration
      worker_cls: vllm_omni.worker.gpu_ar_worker.GPUARWorker
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler
      gpu_memory_utilization: 0.6
      enforce_eager: false
      trust_remote_code: true
      engine_output_type: token_ids # Output prior_token_ids for diffusion stage
      distributed_executor_backend: "mp"
      enable_prefix_caching: false
      max_num_batched_tokens: 32768
      hf_config_name: vision_language_encoder # Subfolder in model path
    final_output: false # AR is not the final output
    is_comprehension: true
    default_sampling_params:
      temperature: 0.0
      top_p: 1.0
      top_k: -1
      max_tokens: 16384 # Support up to 2048x2048 images (64x64 tokens * 4 = 16384)
      seed: 42
      detokenize: false

  # Stage 1: Diffusion (DiT + VAE)
  # This stage receives prior_token_ids from AR and performs denoising + VAE decode
  - stage_id: 1
    stage_type: diffusion
    runtime:
      process: true
      devices: "1" # Can use different GPU, or same GPU if memory allows
      max_batch_size: 1
    engine_args:
      model_arch: GlmImagePipeline
      model_stage: dit
      # Diffusion-specific parameters
      num_gpus: 1
      cfg_parallel_size: 1 # Set to 2 for CFG parallelism on 2 GPUs
      enforce_eager: true
      trust_remote_code: true
      engine_output_type: image # Final output is image
      distributed_executor_backend: "mp"
      enable_prefix_caching: false
    engine_input_source: [0] # Input from AR stage
    custom_process_input_func: vllm_omni.model_executor.stage_input_processors.glm_image.ar2diffusion
    final_output: true
    final_output_type: image
    is_comprehension: false
    default_sampling_params:
      temperature: 0.0
      top_p: 1.0
      top_k: -1
      seed: 42
      detokenize: true
      num_inference_steps: 50
      guidance_scale: 1.5
      height: 1024
      width: 1024

# Top-level runtime config
runtime:
  enabled: true
  defaults:
    window_size: -1 # Trigger downstream only after full upstream completion
    max_inflight: 1 # Process serially within each stage

  edges:
    - from: 0 # AR â†’ Diffusion: trigger after AR completes
      to: 1
      window_size: -1
